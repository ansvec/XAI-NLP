# Diplomová práca - Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka

## Prehľad problematiky
Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka (NLP) je dôležitou témou výskumu, pretože tieto modely sa často používajú na prijímanie rozhodnutí alebo predpovedí s významnými dôsledkami, napríklad v oblasti zdravotníctva a financií. Vysvetliteľnosť sa vzťahuje na schopnosť pochopiť a vysvetliť, ako model robí rozhodnutia alebo predpovede. V prípade modelov NLP to zahŕňa pochopenie toho, ako model spracováva a interpretuje jazyk.
Jednou z výziev pri dosahovaní vysvetliteľnosti pre modely NLP je, že tieto modely často používajú hlboké neurónové siete, ktoré sú zložité a môžu mať mnoho vrstiev a milióny parametrov. Táto zložitosť môže sťažiť pochopenie toho, ako model robí rozhodnutia, a identifikovať akékoľvek potenciálne skreslenia v modeli.

 
## Experimenty

- Klasifikácia dokumentov (na úrovni dokumentov)
- Analýza sentimentu
- Extrahovanie pomenovaných entít (na úrovni slov - tokenov)
- Part of speach tagging, 
- Dependency Parsing

### Prístup ###
1. Popis problematiky
2. Popis dátovej množiny na účely výskumu 
3. Popis vyhodnocovacích metrík
4. Predspracovanie dát
5. Vytvorenie modelov
7. Aplikácia vysvetliteľnosti modelov 
8. Evaluácia výsledkov
