# Diplomová práca - Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka

## Prehľad problematiky
Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka (NLP) je dôležitou témou výskumu, pretože tieto modely sa často používajú na prijímanie rozhodnutí alebo predpovedí s významnými dôsledkami, napríklad v oblasti zdravotníctva a financií. Vysvetliteľnosť sa vzťahuje na schopnosť pochopiť a vysvetliť, ako model robí rozhodnutia alebo predpovede. V prípade modelov NLP to zahŕňa pochopenie toho, ako model spracováva a interpretuje jazyk.
Jednou z výziev pri dosahovaní vysvetliteľnosti pre modely NLP je, že tieto modely často používajú hlboké neurónové siete, ktoré sú zložité a môžu mať mnoho vrstiev a milióny parametrov. Táto zložitosť môže sťažiť pochopenie toho, ako model robí rozhodnutia, a identifikovať akékoľvek potenciálne skreslenia v modeli.
 
## Experimenty

Klasifikácia dokumentov (na úrovni dokumentov)
Extrahovanie pomenovaných entít (na úrovni slov - tokenov)
Part of speach tagging, 
Dependency Parsing

## Prístup
Analýza dátovej množiny na účely výskumu
Predspracovanie textu
Rozdelenie datasetu
Vytvorenie modelu
Trénovanie modelu
Predikcia modelu
Aplikácia vysvetliteľnosti modelov 
Evaluácia výsledkov
