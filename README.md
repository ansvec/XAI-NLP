# Diplomová práca - Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka

## Prehľad problematiky
Vysvetliteľnosť hlbokých sietí pre spracovanie prirodzeného jazyka (NLP) je dôležitou témou výskumu, pretože tieto modely sa často používajú na prijímanie rozhodnutí alebo predpovedí s významnými dôsledkami, napríklad v oblasti zdravotníctva a financií. Vysvetliteľnosť sa vzťahuje na schopnosť pochopiť a vysvetliť, ako model robí rozhodnutia alebo predpovede. V prípade modelov NLP to zahŕňa pochopenie toho, ako model spracováva a interpretuje jazyk.
Jednou z výziev pri dosahovaní vysvetliteľnosti pre modely NLP je, že tieto modely často používajú hlboké neurónové siete, ktoré sú zložité a môžu mať mnoho vrstiev a milióny parametrov. Táto zložitosť môže sťažiť pochopenie toho, ako model robí rozhodnutia, a identifikovať akékoľvek potenciálne skreslenia v modeli.
 
## Experimenty

- Klasifikácia dokumentov (na úrovni dokumentov)
- Extrahovanie pomenovaných entít (na úrovni slov - tokenov)
- Part of speach tagging, 
- Dependency Parsing

### Prístup ###
1. Analýza dátovej množiny na účely výskumu 
2. Predspracovanie textu 
3. Rozdelenie datasetu 
4. Vytvorenie modelu 
5. Trénovanie modelu 
6. Predikcia modelu 
7. Aplikácia vysvetliteľnosti modelov 
8. Evaluácia výsledkov
